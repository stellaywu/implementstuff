{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "import utils2; importlib.reload(utils2)\n",
    "from utils2 import *\n",
    "np.set_printoptions(4)\n",
    "PATH = '/home/ubuntu/data/spellbee/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "limit_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = [l.strip().split(\"  \") for l in open(PATH+\"cmudict-0.7b\", encoding='latin1') \n",
    "         if re.match('^[A-Z]', l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('A', ['AH0']), ('ZYWICKI', ['Z', 'IH0', 'W', 'IH1', 'K', 'IY0']))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines=[(w, ps.split()) for w, ps in lines]\n",
    "lines[0], lines[-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133779"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_', 'AA0', 'AA1', 'AA2', 'AE0']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phonemes=[\"_\"] + sorted(set(p for w, ps in lines for p in ps))\n",
    "phonemes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(phonemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Then we create mappings of phonemes and letters to respective indices.\n",
    "Our letters include the padding element \"_\", but also \"*\" which we'll explain later.'''\n",
    "p2i = dict((v, k) for k, v in enumerate(phonemes))\n",
    "letters=\"_abcdefghijklmnopqrstuvwxyz*\"\n",
    "l2i=dict((v,k) for k, v in enumerate(letters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p2i), len(l2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''create a dictionary mapping words to the sequence of indices corresponding to it's phonemes, \n",
    "only for words between 5 - 15 characters'''\n",
    "maxlen=15\n",
    "pronounce_dict={w.lower(): [p2i[p] for p in ps] for w, ps in lines if (5<=len(w)<=maxlen) and re.match(\"^[A-Z]+$\",w)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for w, ps in lines[:20]:\n",
    "#     if (5<=len(w)<=maxlen) and re.match(\"^[A-Z]+$\",w):\n",
    "# #         print(w, ps)\n",
    "#         print(w.lower())\n",
    "#         for p in ps:\n",
    "#             print(p, p2i[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108006"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pronounce_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x', 'y', 'z', 'a', 'b', 'c']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ['xyz','abc']\n",
    "[o.upper() for o in a if o[0]=='x']\n",
    "[[p for p in o] for o in a]\n",
    "[p for o in a for p in o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split lines into words, phonemes, convert to indexes (with padding), split into training, validation, test sets. \n",
    "# Note we also find the max phoneme sequence length for padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen_p = max([len(v) for k, v in pronounce_dict.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs=np.random.permutation(list(pronounce_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((108006, 16), (108006, 15), 108006)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=len(pairs)\n",
    "input_=np.zeros((n, maxlen_p), np.int32)\n",
    "labels_=np.zeros((n, maxlen), np.int32)\n",
    "input_.shape, labels_.shape, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[58, 8, 44, 21]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronounce_dict['thumbed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108006, 16)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i , k in enumerate(pairs):\n",
    "    for j, p in enumerate(pronounce_dict[k]): \n",
    "#         print(j, p)\n",
    "        input_[i][j]=p\n",
    "    for j, letter in enumerate(k): \n",
    "#         print(j, letter)\n",
    "        labels_[i][j]= l2i[letter]\n",
    "        \n",
    "input_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "go_token=l2i[\"*\"]\n",
    "dec_input_=np.concatenate([np.ones((n,1)) * go_token, labels_[:,:-1]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((108006, 1), (108006, 14))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.ones((n,1)) * go_token).shape,labels_[:,:-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(input_train, input_test, labels_train, labels_test, \n",
    " dec_input_train, dec_input_test) = train_test_split(input_, \n",
    "                    labels_, dec_input_, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((97205, 16), (97205, 15))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train.shape,labels_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 28)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vocab_size, output_vocab_size = len(phonemes), len(letters)\n",
    "input_vocab_size, output_vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parms={'verbose':0, 'callbacks':[TQDMNotebookCallback(leave_inner=True)]}\n",
    "lstm_params={}\n",
    "dim=240"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### without attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rnn(return_sequences=True):\n",
    "    return LSTM(dim, dropout=0.1,recurrent_dropout=0.1, \n",
    "                implementation=2,\n",
    "                return_sequences=return_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 16)\n",
      "(?, 16, 120)\n",
      "(?, ?, 480)\n",
      "(?, 240)\n",
      "(?, 15, 240)\n",
      "(?, ?, 240)\n",
      "(?, ?, 240)\n",
      "(?, 15, 28)\n"
     ]
    }
   ],
   "source": [
    "# get_rnn return sequence = True default \n",
    "\n",
    "inp = Input((maxlen_p,))\n",
    "\n",
    "print(inp.shape)\n",
    "x = Embedding(input_vocab_size, 120)(inp)\n",
    "\n",
    "print(x.shape)\n",
    "x = Bidirectional(get_rnn())(x)\n",
    "print(x.shape)\n",
    "x = get_rnn(False)(x)\n",
    "print(x.shape)\n",
    "x = RepeatVector(maxlen)(x)\n",
    "print(x.shape)\n",
    "x = get_rnn()(x)\n",
    "print(x.shape)\n",
    "x=get_rnn()(x)\n",
    "print(x.shape)\n",
    "x=TimeDistributed(Dense(output_vocab_size, activation='softmax'))(x)\n",
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 16, 120)           8400      \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 16, 480)           693120    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 240)               692160    \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 15, 240)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 15, 240)           461760    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 15, 240)           461760    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 15, 28)            6748      \n",
      "=================================================================\n",
      "Total params: 2,323,948\n",
      "Trainable params: 2,323,948\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inp, x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(Adam(), 'sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3addf8b2c1b4551b45a54187bebf38d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21ad5e98a0d0450e9a64cb4dd7dd5803"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "          \r",
      "97152/|/[loss: 1.517, acc: 0.553] 100%|| 97152/97205 [15:00<00:00, 110.22it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55121a55062342e7bfc0e1904987cf3b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "          \r",
      "97152/|/[loss: 1.047, acc: 0.667] 100%|| 97152/97205 [14:59<00:00, 111.07it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4231b35f8b8a477e97f235f05ee74ff3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist=model.fit(input_train, np.expand_dims(labels_train,-1), \n",
    "          validation_data=[input_test, np.expand_dims(labels_test,-1)], \n",
    "          batch_size=64, **parms, nb_epoch=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_keras(input):\n",
    "    preds = model.predict(input, batch_size=128)\n",
    "    predict = np.argmax(preds, axis = 2)\n",
    "    return (np.mean([all(real==p) for real, p in zip(labels_test, predict)]), predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, preds = eval_keras(input_test); acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_examples(preds):\n",
    "    print(\"pronunciation\".ljust(40), \"real spelling\".ljust(17), \n",
    "          \"model spelling\".ljust(17), \"is correct\")\n",
    "\n",
    "    for index in range(20):\n",
    "        ps = \"-\".join([phonemes[p] for p in input_test[index]]) \n",
    "        real = [letters[l] for l in labels_test[index]] \n",
    "        predict = [letters[l] for l in preds[index]]\n",
    "        print (ps.split(\"-_\")[0].ljust(40), \"\".join(real).split(\"_\")[0].ljust(17),\n",
    "            \"\".join(predict).split(\"_\")[0].ljust(17), str(real == predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pronunciation                            real spelling     model spelling    is correct\n",
      "K-AE1-K-AH0-L                            cackle            cackll            False\n",
      "D-IH0-M-AA1-R-IY0-AH0                    demaria           dimaria           False\n",
      "M-AH0-K-L-EH1-L-AH0-N-D                  mcclelland        mclleland         False\n",
      "D-R-AH0-M-AE1-T-IH0-K-S                  dramatics         dramattis         False\n",
      "Z-AY1-L-IH0-N-AH0                        xylina            zilina            False\n",
      "S-EH1-N                                  senne             senne             True\n",
      "S-AH0-B-S-IH1-S-T                        subsist           subsist           True\n",
      "D-IH0-T-IH1-R-IY0-ER0-EY2-T-S            deteriorates      deterrrrattt      False\n",
      "B-L-EH1-R                                blare             bleer             False\n",
      "M-EH1-L-K-AA2-R                          melkar            milcar            False\n",
      "T-EH2-K-T-R-AA1-N-IH0-K-S                tektronix         tectranicc        False\n",
      "N-IY0-D-B-AA1-L-S-K-IY0                  niedbalski        nedbllsk          False\n",
      "V-IY0-N-CH-IY0-G-EH1-R-AH0               vinciguerra       venchigra         False\n",
      "SH-IH1-L-IY0                             shiley            shilly            False\n",
      "L-EY1-M-IY0                              lamie             lammy             False\n",
      "V-IY0-S-K-UW1-S-IY0                      viscusi           viskosi           False\n",
      "R-UW1-B-IY0-Z                            rubies            robbes            False\n",
      "P-EH1-T-R-AH0-S                          petrus            petrass           False\n",
      "R-EH1-Z-L-ER0                            resler            resllr            False\n",
      "S-K-AE2-N-D-IH0-N-AH0-V-IH1-S-K-AH0      skandinaviska     scandiniiiiii     False\n"
     ]
    }
   ],
   "source": [
    "print_examples(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'importlib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-267fe436c150>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mattention_wrapper\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mattention_wrapper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAttention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# teacher forcing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'importlib' is not defined"
     ]
    }
   ],
   "source": [
    "import attention_wrapper; importlib.reload(attention_wrapper)\n",
    "from attention_wrapper import Attention\n",
    "# teacher forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 16) (?, 15)\n"
     ]
    }
   ],
   "source": [
    "inp = Input((maxlen_p,))\n",
    "inp_dec = Input((maxlen,))\n",
    "print(inp.shape, inp_dec.shape)\n",
    "emb_dec = Embedding(output_vocab_size, 120)(inp_dec)\n",
    "emb_dec = Dense(dim)(emb_dec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?Attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 16, 120)\n",
      "(?, ?, 480)\n",
      "(?, ?, 240)\n",
      "(?, ?, 240)\n"
     ]
    }
   ],
   "source": [
    "x= Embedding(input_vocab_size, 120)(inp)\n",
    "print(x.shape)\n",
    "x= Bidirectional(get_rnn())(x)\n",
    "print(x.shape)\n",
    "x = get_rnn()(x)\n",
    "print(x.shape)\n",
    "x = get_rnn()(x)\n",
    "print(x.shape)\n",
    "x = Attention(get_rnn, 3)([x, emb_dec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
