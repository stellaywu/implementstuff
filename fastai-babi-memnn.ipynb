{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import importlib, utils2; importlib.reload(utils2)\n",
    "from utils2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(4)\n",
    "cfg= K.tf.ConfigProto(gpu_options={'allow_growth':True})\n",
    "K.set_session(K.tf.Session(config=cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "    return [x.strip() for x in re.split('(\\W+)?', sent) if x.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_stories(lines):\n",
    "    data = []\n",
    "    story = []\n",
    "    for line in lines:\n",
    "        line = line.decode('utf-8').strip()\n",
    "        nid, line = line.split(' ', 1)\n",
    "        if int(nid) == 1: story = []\n",
    "        if '\\t' in line:\n",
    "            q, a, supporting = line.split('\\t')\n",
    "            q = tokenize(q)\n",
    "            substory = None\n",
    "            substory = [[str(i)+\":\"]+x for i,x in enumerate(story) if x]\n",
    "            data.append((substory, q, a))\n",
    "            story.append('')\n",
    "        else: story.append(tokenize(line))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = get_file('babi-tasks-v1-2.tar.gz', \n",
    "                origin='https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz')\n",
    "tar = tarfile.open(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "challenges = {\n",
    "    # QA1 with 10,000 samples\n",
    "    'single_supporting_fact_10k': 'tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_{}.txt',\n",
    "    # QA2 with 10,000 samples\n",
    "    'two_supporting_facts_10k': 'tasks_1-20_v1-2/en-10k/qa2_two-supporting-facts_{}.txt',\n",
    "    'two_supporting_facts_1k': 'tasks_1-20_v1-2/en/qa2_two-supporting-facts_{}.txt',\n",
    "}\n",
    "challenge_type = 'single_supporting_fact_10k'\n",
    "challenge_type = 'two_supporting_facts_10k'\n",
    "challenge = challenges[challenge_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stories(f):\n",
    "    data = parse_stories(f.readlines())\n",
    "    return [(story, q, answer) for story, q, answer in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "train_stories = get_stories(tar.extractfile(challenge.format('train')))\n",
    "test_stories = get_stories(tar.extractfile(challenge.format('test')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stories = train_stories + test_stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11000"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['0:', 'Mary', 'moved', 'to', 'the', 'bathroom', '.'],\n",
       "  ['1:', 'Sandra', 'journeyed', 'to', 'the', 'bedroom', '.'],\n",
       "  ['2:', 'Mary', 'got', 'the', 'football', 'there', '.'],\n",
       "  ['3:', 'John', 'went', 'to', 'the', 'kitchen', '.'],\n",
       "  ['4:', 'Mary', 'went', 'back', 'to', 'the', 'kitchen', '.'],\n",
       "  ['5:', 'Mary', 'went', 'back', 'to', 'the', 'garden', '.']],\n",
       " ['Where', 'is', 'the', 'football', '?'],\n",
       " 'garden')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stories[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_maxlen=max((len(s) for x, _, _ in stories for s in x))\n",
    "story_maxsents = max((len(x) for x, _, _ in stories))\n",
    "query_maxlen = max(len(x) for _, x, _ in stories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_flatten(el):\n",
    "    return isinstance(el, collections.Iterable) and not isinstance(el, (str, bytes))\n",
    "def flatten(l):\n",
    "    for el in l:\n",
    "        if do_flatten(el): yield from flatten(el)\n",
    "        else: yield el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<PAD', '.', '0:', '10:', '11:', '12:', '13:', '14:', '15:', '16:', '17:', '18:', '19:', '1:', '20:', '21:', '22:', '23:', '24:', '25:', '26:', '27:', '28:', '29:', '2:', '30:', '31:', '32:', '33:', '34:', '35:', '36:', '37:', '38:', '39:', '3:', '40:', '41:', '42:', '43:', '44:', '45:', '46:', '47:', '48:', '49:', '4:', '50:', '51:', '52:', '53:', '54:', '55:', '56:', '57:', '58:', '59:', '5:', '60:', '61:', '62:', '63:', '64:', '65:', '66:', '67:', '68:', '69:', '6:', '70:', '71:', '72:', '73:', '74:', '75:', '76:', '77:', '78:', '79:', '7:', '81:', '82:', '84:', '85:', '87:', '88:', '8:', '90:', '91:', '9:', '?', 'Daniel', 'John', 'Mary', 'Sandra', 'Where', 'apple', 'back', 'bathroom', 'bedroom', 'discarded', 'down', 'dropped', 'football', 'garden', 'got', 'grabbed', 'hallway', 'is', 'journeyed', 'kitchen', 'left', 'milk', 'moved', 'office', 'picked', 'put', 'the', 'there', 'to', 'took', 'travelled', 'up', 'went']\n"
     ]
    }
   ],
   "source": [
    "# Create vocabulary of corpus and find size, including a padding element.\n",
    "vocab = sorted(set(flatten(stories)))\n",
    "vocab.insert(0, '<PAD')\n",
    "print(vocab)\n",
    "vocab_size=len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 124, 8, 5, 10000, 1000)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_maxsents, vocab_size, story_maxlen, query_maxlen, len(train_stories), len(test_stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' can backward through the sentences to find the answer to the question '"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' can backward through the sentences to find the answer to the question '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 1,\n",
       " '0:': 2,\n",
       " '10:': 3,\n",
       " '11:': 4,\n",
       " '12:': 5,\n",
       " '13:': 6,\n",
       " '14:': 7,\n",
       " '15:': 8,\n",
       " '16:': 9,\n",
       " '17:': 10,\n",
       " '18:': 11,\n",
       " '19:': 12,\n",
       " '1:': 13,\n",
       " '20:': 14,\n",
       " '21:': 15,\n",
       " '22:': 16,\n",
       " '23:': 17,\n",
       " '24:': 18,\n",
       " '25:': 19,\n",
       " '26:': 20,\n",
       " '27:': 21,\n",
       " '28:': 22,\n",
       " '29:': 23,\n",
       " '2:': 24,\n",
       " '30:': 25,\n",
       " '31:': 26,\n",
       " '32:': 27,\n",
       " '33:': 28,\n",
       " '34:': 29,\n",
       " '35:': 30,\n",
       " '36:': 31,\n",
       " '37:': 32,\n",
       " '38:': 33,\n",
       " '39:': 34,\n",
       " '3:': 35,\n",
       " '40:': 36,\n",
       " '41:': 37,\n",
       " '42:': 38,\n",
       " '43:': 39,\n",
       " '44:': 40,\n",
       " '45:': 41,\n",
       " '46:': 42,\n",
       " '47:': 43,\n",
       " '48:': 44,\n",
       " '49:': 45,\n",
       " '4:': 46,\n",
       " '50:': 47,\n",
       " '51:': 48,\n",
       " '52:': 49,\n",
       " '53:': 50,\n",
       " '54:': 51,\n",
       " '55:': 52,\n",
       " '56:': 53,\n",
       " '57:': 54,\n",
       " '58:': 55,\n",
       " '59:': 56,\n",
       " '5:': 57,\n",
       " '60:': 58,\n",
       " '61:': 59,\n",
       " '62:': 60,\n",
       " '63:': 61,\n",
       " '64:': 62,\n",
       " '65:': 63,\n",
       " '66:': 64,\n",
       " '67:': 65,\n",
       " '68:': 66,\n",
       " '69:': 67,\n",
       " '6:': 68,\n",
       " '70:': 69,\n",
       " '71:': 70,\n",
       " '72:': 71,\n",
       " '73:': 72,\n",
       " '74:': 73,\n",
       " '75:': 74,\n",
       " '76:': 75,\n",
       " '77:': 76,\n",
       " '78:': 77,\n",
       " '79:': 78,\n",
       " '7:': 79,\n",
       " '81:': 80,\n",
       " '82:': 81,\n",
       " '84:': 82,\n",
       " '85:': 83,\n",
       " '87:': 84,\n",
       " '88:': 85,\n",
       " '8:': 86,\n",
       " '90:': 87,\n",
       " '91:': 88,\n",
       " '9:': 89,\n",
       " '<PAD': 0,\n",
       " '?': 90,\n",
       " 'Daniel': 91,\n",
       " 'John': 92,\n",
       " 'Mary': 93,\n",
       " 'Sandra': 94,\n",
       " 'Where': 95,\n",
       " 'apple': 96,\n",
       " 'back': 97,\n",
       " 'bathroom': 98,\n",
       " 'bedroom': 99,\n",
       " 'discarded': 100,\n",
       " 'down': 101,\n",
       " 'dropped': 102,\n",
       " 'football': 103,\n",
       " 'garden': 104,\n",
       " 'got': 105,\n",
       " 'grabbed': 106,\n",
       " 'hallway': 107,\n",
       " 'is': 108,\n",
       " 'journeyed': 109,\n",
       " 'kitchen': 110,\n",
       " 'left': 111,\n",
       " 'milk': 112,\n",
       " 'moved': 113,\n",
       " 'office': 114,\n",
       " 'picked': 115,\n",
       " 'put': 116,\n",
       " 'the': 117,\n",
       " 'there': 118,\n",
       " 'to': 119,\n",
       " 'took': 120,\n",
       " 'travelled': 121,\n",
       " 'up': 122,\n",
       " 'went': 123}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create index mapping for the vocabulary\n",
    "word_idx = dict((c, i) for i, c in enumerate(vocab))\n",
    "word_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_idx, story_maxlen, query_maxlen):\n",
    "    X = []; Xq = []; Y = []\n",
    "    for story, query, answer in data:\n",
    "        x = [[word_idx[w] for w in s] for s in story]\n",
    "        xq = [word_idx[w] for w in query]\n",
    "        y = [word_idx[answer]]\n",
    "        X.append(x); Xq.append(xq); Y.append(y)\n",
    "    return ([pad_sequences(x, maxlen=story_maxlen) for x in X],\n",
    "            pad_sequences(Xq, maxlen=query_maxlen), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(train_stories, \n",
    "     word_idx, story_maxlen, query_maxlen)\n",
    "inputs_test, queries_test, answers_test = vectorize_stories(test_stories, \n",
    "     word_idx, story_maxlen, query_maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   2,  93, 113, 119, 117,  98,   1],\n",
       "       [  0,  13,  94, 109, 119, 117,  99,   1],\n",
       "       [  0,  24,  93, 105, 117, 103, 118,   1],\n",
       "       [  0,  35,  92, 123, 119, 117, 110,   1],\n",
       "       [ 46,  93, 123,  97, 119, 117, 110,   1],\n",
       "       [ 57,  93, 123,  97, 119, 117, 104,   1]], dtype=int32)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs_train[0])\n",
    "inputs_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78, 8)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(story_maxsents-it.shape[0],story_maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''padding the matrix to have the same shape'''\n",
    "def stack_inputs(inputs):\n",
    "    for i,it in enumerate(inputs):\n",
    "        inputs[i] = np.concatenate([it, \n",
    "                           np.zeros((story_maxsents-it.shape[0],story_maxlen), 'int')])\n",
    "    return np.stack(inputs)\n",
    "inputs_train = stack_inputs(inputs_train)\n",
    "inputs_test = stack_inputs(inputs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inps = [inputs_train, queries_train]\n",
    "val_inps = [inputs_test, queries_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 5), (1000, 5))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inps), len(val_inps)\n",
    "queries_train.shape, queries_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 95, 108, 117, 103,  90], dtype=int32)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_train[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 88, 8)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adding up the word embeddings\n",
    "emb_dim = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parms = {'verbose': 2, 'callbacks': [TQDMNotebookCallback(leave_inner=False)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The embedding works as desired; the raw input has 10 sentences of 8 words, \n",
    "# and the output has 10 sentence embeddings of length 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''TimeDistributed here to apply the embedding to every element of the sequence, then the Lambda layer adds them up'''\n",
    "def emb_sent_bow(inp):\n",
    "    emb = TimeDistributed(Embedding(vocab_size, emb_dim))(inp)\n",
    "    return Lambda(lambda x: K.sum(x, 2))(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(None), Dimension(10), Dimension(8)]),\n",
       " TensorShape([Dimension(None), Dimension(10), Dimension(20)]))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_story = Input((story_maxsents, story_maxlen))\n",
    "emb_story = emb_sent_bow(inp_story)\n",
    "inp_story.shape, emb_story.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  We do the same for the queries, omitting the TimeDistributed since there is only one query. \n",
    "# We use Reshape to match the rank of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 20, TensorShape([Dimension(None), Dimension(4)]))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size, emb_dim, Input((query_maxlen,)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 4, 20)\n",
      "(?, 20)\n",
      "(?, 1, 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(None), Dimension(4)]),\n",
       " TensorShape([Dimension(None), Dimension(1), Dimension(20)]))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_q = Input((query_maxlen,))\n",
    "emb_q = Embedding(vocab_size, emb_dim)(inp_q)\n",
    "print(emb_q.shape)\n",
    "emb_q = Lambda(lambda x: K.sum(x, 1))(emb_q)\n",
    "print(emb_q.shape)\n",
    "emb_q = Reshape((1, emb_dim))(emb_q)\n",
    "print(emb_q.shape)\n",
    "inp_q.shape, emb_q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(None), Dimension(10), Dimension(20)]),\n",
       " TensorShape([Dimension(None), Dimension(1), Dimension(20)]))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_story.shape, emb_q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 10)\n",
      "(?, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/legacy/layers.py:460: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(10), Dimension(1)])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = merge([emb_story, emb_q], mode='dot', dot_axes=2)\n",
    "x = Reshape((story_maxsents,))(x)\n",
    "print(x.shape)\n",
    "x = Activation('softmax')(x)\n",
    "print(x.shape)\n",
    "match = Reshape((story_maxsents,1))(x)\n",
    "match.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 1, 20)\n",
      "(?, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  \n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/legacy/layers.py:460: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(32)])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_c = emb_sent_bow(inp_story)\n",
    "x = merge([match, emb_c], mode='dot', dot_axes=1)\n",
    "print(x.shape)\n",
    "response = Reshape((emb_dim,))(x)\n",
    "print(response.shape)\n",
    "res = Dense(vocab_size, activation='softmax')(response)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answer = Model([inp_story, inp_q], res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_8 (InputLayer)             (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_1 (InputLayer)             (None, 10, 8)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)          (None, 4, 20)         640         input_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistribu (None, 10, 8, 20)     640         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)                (None, 20)            0           embedding_6[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)                (None, 10, 20)        0           time_distributed_1[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)              (None, 1, 20)         0           lambda_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, 10, 1)         0           lambda_1[0][0]                   \n",
      "                                                                   reshape_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)              (None, 10)            0           merge_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 10)            0           reshape_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistribu (None, 10, 8, 20)     640         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)              (None, 10, 1)         0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)                (None, 10, 20)        0           time_distributed_3[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "merge_3 (Merge)                  (None, 1, 20)         0           reshape_7[0][0]                  \n",
      "                                                                   lambda_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)              (None, 20)            0           merge_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 32)            672         reshape_9[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 2,592\n",
      "Trainable params: 2,592\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "answer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answer.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e71c4af0403e415884f04e9c62b56a22"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfe32e407a224af596bcd0692ed48b57"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1s - loss: 0.4366 - acc: 0.8475 - val_loss: 6.9708e-05 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "463632c0198d4e7fbe78539c3096bf54"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/4\n",
      "1s - loss: 0.0076 - acc: 0.9983 - val_loss: 2.0632e-04 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27af03891aca4a03a872e0acdf0a7206"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/4\n",
      "1s - loss: 0.0066 - acc: 0.9989 - val_loss: 0.1009 - val_acc: 0.9850\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f457a17e6d4d4b0a8dd3bdd760e934fd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/4\n",
      "1s - loss: 0.0060 - acc: 0.9989 - val_loss: 5.6249e-06 - val_acc: 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "K.set_value(answer.optimizer.lr, 1e-2)\n",
    "hist=answer.fit(inps, answers_train, **parms, nb_epoch=4, batch_size=32,\n",
    "                validation_data=(val_inps, answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = Model([inp_story, inp_q], match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qnum=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['0:', 'Sandra', 'travelled', 'to', 'the', 'office', '.'],\n",
       "  ['1:', 'Sandra', 'went', 'to', 'the', 'bathroom', '.'],\n",
       "  ['3:', 'Mary', 'went', 'to', 'the', 'bedroom', '.'],\n",
       "  ['4:', 'Daniel', 'moved', 'to', 'the', 'hallway', '.']],\n",
       " ['Where', 'is', 'Sandra', '?'],\n",
       " 'bathroom')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_st = len(train_stories[qnum][0])+1\n",
    "train_stories[qnum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.4209e-02,   9.7572e-01,   1.2684e-05,   6.2878e-05,   1.1691e-09], dtype=float32)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(f.predict([inputs_train[qnum:qnum+1], queries_train[qnum:qnum+1]]))[:l_st]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19, 19, 27, 22, 19, 20, 19, 19, 20, 20])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_train[qnum:qnum+10,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19, 19, 27, 22, 19, 20, 19, 19, 20, 20])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(answer.predict([inputs_train[qnum:qnum+10], queries_train[qnum:qnum+10]]), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.2020e-12,   7.6779e-13,   1.3014e-12,   8.0154e-13,\n",
       "          7.8482e-13,   5.9923e-13,   7.9556e-13,   8.9453e-13,\n",
       "          2.5134e-12,   1.2741e-12,   1.2244e-12,   3.9635e-13,\n",
       "          7.2166e-13,   4.6996e-13,   8.0795e-13,   1.0314e-12,\n",
       "          7.7528e-13,   5.7153e-13,   6.4650e-13,   1.0000e+00,\n",
       "          8.8141e-11,   4.6416e-11,   4.0828e-12,   1.0003e-12,\n",
       "          6.0218e-13,   1.4031e-10,   1.3553e-12,   4.7173e-11,\n",
       "          8.7698e-13,   7.1562e-13,   4.2013e-13,   6.9185e-13]], dtype=float32)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer.predict([inputs_train[qnum:qnum+1], queries_train[qnum:qnum+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bathroom'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vocab[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TWO surpport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 88, 8), (1000, 88, 8))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_train.shape, inputs_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "parms = {'verbose': 2, 'callbacks': [TQDMNotebookCallback(leave_inner=False)]}\n",
    "emb_dim = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def emb_sent_bow(inp):\n",
    "    emb_op = TimeDistributed(Embedding(vocab_size, emb_dim))\n",
    "    emb = emb_op(inp)\n",
    "    emb = Lambda(lambda x: K.sum(x, 2))(emb)\n",
    "#     return Elemwise(0, False)(emb), emb_op\n",
    "    return emb, emb_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp_story = Input((story_maxsents, story_maxlen))\n",
    "inp_q = Input((query_maxlen,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_story, emb_story_op = emb_sent_bow(inp_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_q = emb_story_op.layer(inp_q)\n",
    "emb_q = Lambda(lambda x: K.sum(x, 1))(emb_q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = Dense(emb_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hop(u, A):\n",
    "    C, _ = emb_sent_bow(inp_story)\n",
    "    x = Reshape((1, emb_dim))(u)\n",
    "    x = merge([A, x], mode='dot', dot_axes=2)\n",
    "    x = Reshape((story_maxsents,))(x)\n",
    "    x = Activation('softmax')(x)\n",
    "    match = Reshape((story_maxsents,1))(x)\n",
    "\n",
    "    x = merge([match, C], mode='dot', dot_axes=1)\n",
    "    x = Reshape((emb_dim,))(x)\n",
    "    x = h(x)\n",
    "    x = merge([x, emb_q], 'sum')\n",
    "    return x, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  after removing the cwd from sys.path.\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/legacy/layers.py:460: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  if __name__ == '__main__':\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "response, emb_story = one_hop(emb_q, emb_story)\n",
    "response, emb_story = one_hop(response, emb_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = Dense(vocab_size, activation='softmax')(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answer = Model([inp_story, inp_q], res)\n",
    "answer.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_10 (InputLayer)            (None, 5)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_9 (InputLayer)             (None, 88, 8)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)          (None, 5, 30)         3720        input_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistribu (None, 88, 8, 30)     3720        input_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)               (None, 30)            0           embedding_9[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)                (None, 88, 30)        0           time_distributed_4[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)             (None, 1, 30)         0           lambda_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_4 (Merge)                  (None, 88, 1)         0           lambda_9[0][0]                   \n",
      "                                                                   reshape_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)             (None, 88)            0           merge_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistribu (None, 88, 8, 30)     3720        input_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 88)            0           reshape_11[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)               (None, 88, 30)        0           time_distributed_5[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "reshape_12 (Reshape)             (None, 88, 1)         0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "merge_5 (Merge)                  (None, 1, 30)         0           reshape_12[0][0]                 \n",
      "                                                                   lambda_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "reshape_13 (Reshape)             (None, 30)            0           merge_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 30)            930         reshape_13[0][0]                 \n",
      "                                                                   reshape_17[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "merge_6 (Merge)                  (None, 30)            0           dense_3[0][0]                    \n",
      "                                                                   lambda_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "reshape_14 (Reshape)             (None, 1, 30)         0           merge_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "merge_7 (Merge)                  (None, 88, 1)         0           lambda_11[0][0]                  \n",
      "                                                                   reshape_14[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "reshape_15 (Reshape)             (None, 88)            0           merge_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 88)            0           reshape_15[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistribu (None, 88, 8, 30)     3720        input_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "reshape_16 (Reshape)             (None, 88, 1)         0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)               (None, 88, 30)        0           time_distributed_6[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "merge_8 (Merge)                  (None, 1, 30)         0           reshape_16[0][0]                 \n",
      "                                                                   lambda_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "reshape_17 (Reshape)             (None, 30)            0           merge_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "merge_9 (Merge)                  (None, 30)            0           dense_3[1][0]                    \n",
      "                                                                   lambda_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 124)           3844        merge_9[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 15,934\n",
      "Trainable params: 15,934\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "answer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3efb06bda1a49d6a82ca8b10852905e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "687f25eb23ff44b59b676d23635b7e21"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "2s - loss: 1.6987 - acc: 0.3014 - val_loss: 1.3912 - val_acc: 0.4800\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "159fc1a241664fa3afa0a60222b30c7d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/8\n",
      "2s - loss: 1.0302 - acc: 0.6133 - val_loss: 0.8364 - val_acc: 0.6890\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40f8f38bee8e4851ab7043f557fa8571"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/8\n",
      "2s - loss: 0.7647 - acc: 0.7253 - val_loss: 0.7557 - val_acc: 0.7500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e6849bcd9a4c18909e013059374c1e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/8\n",
      "2s - loss: 0.6425 - acc: 0.7721 - val_loss: 0.7376 - val_acc: 0.7170\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f4e6039ae946d6bdfce16809aa5d50"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/8\n",
      "2s - loss: 0.5543 - acc: 0.8057 - val_loss: 0.6031 - val_acc: 0.8080\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46d412ce5c934d35be12422b1816bd46"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/8\n",
      "2s - loss: 0.4914 - acc: 0.8388 - val_loss: 0.5991 - val_acc: 0.8120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753fbcc1e7424d108c10b9b969df2621"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/8\n",
      "2s - loss: 0.4583 - acc: 0.8538 - val_loss: 0.5837 - val_acc: 0.8260\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8135bf7f787840d59ce88df89b87c5f1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/8\n",
      "2s - loss: 0.4286 - acc: 0.8686 - val_loss: 0.5450 - val_acc: 0.8340\n",
      "\n"
     ]
    }
   ],
   "source": [
    "K.set_value(answer.optimizer.lr, 5e-3)\n",
    "hist=answer.fit(inps, answers_train, **parms, nb_epoch=8, batch_size=32,\n",
    "           validation_data=(val_inps, answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.48 ,  0.689,  0.75 ,  0.717,  0.808,  0.812,  0.826,  0.834])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(hist.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Elemwise(Layer):\n",
    "    def __init__(self, axis, is_mult, init='glorot_uniform', **kwargs):\n",
    "        self.init = initializations.get(init)\n",
    "        self.axis = axis\n",
    "        self.is_mult = is_mult\n",
    "        super(Elemwise, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_dims = input_shape[1:]\n",
    "        dims = [1] * len(input_dims)\n",
    "        dims[self.axis] = input_dims[self.axis]\n",
    "        self.b = self.add_weight(dims, self.init, '{}_bo'.format(self.name))\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        return x * self.b if self.is_mult else x + self.b\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'init': self.init.__name__, 'axis': self.axis}\n",
    "        base_config = super(Dense, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
